{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Ideas for training\n",
    "1. Instead of [0:5][5:10] as frames we can do [0:5][1:6][2:7]...\n",
    "2. Shuffle TRAIN_ID, VALIDATION_ID, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from ChalearnLAPSample import GestureSample\n",
    "from tqdm import tqdm\n",
    "from scipy.misc import imresize\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy import stats\n",
    "import util\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "TRAIN_ID = range(1,11)         # Raw file format : Sample0001.zip - Sample0470.zip\n",
    "VALIDATION_ID = range(471,481)  # Raw file format : Sample0471.zip - Sample0700.zip\n",
    "TEST_ID = range(701,711)        # Raw file format : Sample0701.zip - Sample0941.zip\n",
    "# TRAIN_LIST = range(1,471)         # Raw file format : Sample0001.zip - Sample0470.zip\n",
    "# VALIDATION_LIST = range(471,701)  # Raw file format : Sample0471.zip - Sample0700.zip\n",
    "# TEST_LIST = range(701,941)        # Raw file format : Sample0701.zip - Sample0941.zip\n",
    "\n",
    "# Original image size is 480x640, crop to 320x320 then resize to 80x80\n",
    "# TODO: change IMAGE_SiIZE, remove downsampling\n",
    "CROP = (10, 330, 140, 460)\n",
    "# RESIZE_RATIO = 0.25\n",
    "IMAGE_SIZE = (320, 320, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "RAW_DATA_PATH = './data/'\n",
    "TFRecord_DATA_PATH = './tf-data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "FRAMES_PER_CLIP = 8\n",
    "MAX_FRAMES = 2000\n",
    "CLIPS_PER_VIDEO = MAX_FRAMES / FRAMES_PER_CLIP\n",
    "\n",
    "'''Self-defined gesture labels'''\n",
    "NO_GESTURE = 21\n",
    "EMPTY_PADDING = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as mpimg\n",
    "# \n",
    "# sample = GestureSample(RAW_DATA_PATH + 'Train/Sample0001.zip')\n",
    "# img = sample.getRGB(1)\n",
    "# print(img.shape)\n",
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Create TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_data(path, data_type, write_path, sample_ids, label_path = None):\n",
    "    for sample_id in tqdm(sample_ids):\n",
    "        \n",
    "        '''Get ChaLearn Data reader'''\n",
    "        if label_path is not None: #data_type == 'Validation'\n",
    "            sample = GestureSample('%s/%s/Sample%04d.zip'%(path, data_type, sample_id), \n",
    "                                   labelFileName=label_path + 'Sample%04d_prediction.csv'%sample_id)\n",
    "        else: # data_type == 'Test', 'Train'\n",
    "            sample = GestureSample('%s/%s/Sample%04d.zip'%(path, data_type, sample_id))\n",
    "            \n",
    "        '''Get label per frame'''\n",
    "        gesture_list = sample.getGestures()\n",
    "        num_of_frames = sample.getNumFrames()\n",
    "        if (num_of_frames > MAX_FRAMES):\n",
    "            raise Exception('Sample %d has %d Frames (> MAX_FRAMES:%d)' %(sample_id, num_of_frames, MAX_FRAMES))\n",
    "            \n",
    "        label = [EMPTY_PADDING] + [NO_GESTURE]* num_of_frames + [EMPTY_PADDING] * (MAX_FRAMES - num_of_frames)\n",
    "        has_label = True if len(gesture_list) > 0 else False\n",
    "        for gesture_id, start_frame, end_frame in gesture_list:\n",
    "            label[start_frame:end_frame+1] = [gesture_id]*(end_frame + 1 - start_frame)\n",
    "        \n",
    "        '''Get sliced and cropped RGB data from the whole sample'''\n",
    "        rgb = [np.zeros(IMAGE_SIZE)]\n",
    "        for f in range(1, MAX_FRAMES+1):\n",
    "            if (f > num_of_frames): # Add 0 paddings\n",
    "                rgb_data = np.zeros(IMAGE_SIZE, dtype=np.uint8)\n",
    "            else: \n",
    "                segmentation_mask = sample.getUser(f)\n",
    "                if (segmentation_mask.sum() == 0):\n",
    "                    label[f] = EMPTY_PADDING\n",
    "                    print('Empty segmentation mask for Sample %d on frame %d' % (sample_id, f))\n",
    "                rgb_data = sample.getRGB(f) * segmentation_mask\n",
    "                rgb_data = rgb_data[CROP[0]:CROP[1], CROP[2]:CROP[3],:]\n",
    "            rgb += [rgb_data]\n",
    "            \n",
    "        '''Make it into clips'''\n",
    "        rgbs = []\n",
    "        labels = []\n",
    "        for f in range(1, MAX_FRAMES+1, FRAMES_PER_CLIP):\n",
    "            rgbs += [np.asarray(rgb[f:f+FRAMES_PER_CLIP])]\n",
    "            labels += [int(stats.mode(label[f:f+FRAMES_PER_CLIP])[0])]\n",
    "            \n",
    "        '''Create TFRecord structure'''\n",
    "        context = tf.train.Features(feature={'sample_id': util._int64_feature(sample_id)})\n",
    "            \n",
    "        featureLists = tf.train.FeatureLists(feature_list={\n",
    "            'rgbs':util._bytes_feature_list(rgbs),\n",
    "            'labels':util._int64_feature_list(labels)\n",
    "        })\n",
    "       \n",
    "        sequence_example = tf.train.SequenceExample(context=context, feature_lists=featureLists)\n",
    "        \n",
    "        '''Write to .tfrecord file'''\n",
    "    \n",
    "        tf_write_option = tf.python_io.TFRecordOptions(compression_type=tf.python_io.TFRecordCompressionType.GZIP)\n",
    "        filename = '%s/%s/Sample%04d.tfrecords' % (write_path, data_type, sample_id)\n",
    "        tf_writer = tf.python_io.TFRecordWriter(filename, options=tf_write_option)\n",
    "        tf_writer.write(sequence_example.SerializeToString())\n",
    "        tf_writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty segmentation mask for Sample 701 on frame 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get features lists\n",
      "get sequence_example\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 1/10 [00:31<04:45, 31.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write first file\n",
      "Empty segmentation mask for Sample 702 on frame 1\n",
      "Empty segmentation mask for Sample 702 on frame 2\n",
      "Empty segmentation mask for Sample 702 on frame 3\n",
      "Empty segmentation mask for Sample 702 on frame 4\n",
      "get features lists\n",
      "get sequence_example\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [00:59<04:05, 30.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write first file\n",
      "Empty segmentation mask for Sample 703 on frame 1\n",
      "Empty segmentation mask for Sample 703 on frame 2\n",
      "Empty segmentation mask for Sample 703 on frame 3\n",
      "get features lists\n",
      "get sequence_example\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9365d292ffb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#get_data(RAW_DATA_PATH, 'Train', TFRecord_DATA_PATH, TRAIN_ID)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#get_data(RAW_DATA_PATH, 'Validation', TFRecord_DATA_PATH, VALIDATION_ID, label_path = RAW_DATA_PATH + 'Validation_reference/')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRAW_DATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTFRecord_DATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTEST_ID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-c653dea7108e>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(path, data_type, write_path, sample_ids, label_path)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%s/%s/Sample%04d.tfrecords'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwrite_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mtf_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFRecordWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf_write_option\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mtf_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_example\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mtf_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'write first file'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#get_data(RAW_DATA_PATH, 'Train', TFRecord_DATA_PATH, TRAIN_ID)\n",
    "#get_data(RAW_DATA_PATH, 'Validation', TFRecord_DATA_PATH, VALIDATION_ID, label_path = RAW_DATA_PATH + 'Validation_reference/')\n",
    "get_data(RAW_DATA_PATH, 'Test', TFRecord_DATA_PATH, TEST_ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
