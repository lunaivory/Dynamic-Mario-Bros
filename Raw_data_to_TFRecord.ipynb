{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideas for training\n",
    "1. Instead of [0:5][5:10] as frames we can do [0:5][1:6][2:7]...\n",
    "2. Shuffle TRAIN_ID, VALIDATION_ID, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from ChalearnLAPSample import GestureSample\n",
    "from tqdm import tqdm\n",
    "from scipy.misc import imresize\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy import stats\n",
    "import util\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_ID = range(1,11)         # Raw file format : Sample0001.zip - Sample0470.zip\n",
    "VALIDATION_ID = range(471,481)  # Raw file format : Sample0471.zip - Sample0700.zip\n",
    "TEST_ID = range(701,711)        # Raw file format : Sample0701.zip - Sample0941.zip\n",
    "# TRAIN_LIST = range(1,471)         # Raw file format : Sample0001.zip - Sample0470.zip\n",
    "# VALIDATION_LIST = range(471,701)  # Raw file format : Sample0471.zip - Sample0700.zip\n",
    "# TEST_LIST = range(701,941)        # Raw file format : Sample0701.zip - Sample0941.zip\n",
    "\n",
    "# Original image size is 480x640, crop to 320x320 then resize to 80x80\n",
    "CROP = (10, 330, 140, 460)\n",
    "RESIZE_RATIO = 0.25\n",
    "IMAGE_SIZE = (80, 80, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RAW_DATA_PATH = './data/'\n",
    "TFRecord_DATA_PATH = './tf-data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FRAMES_PER_CLIP = 5\n",
    "MAX_FRAMES = 2000\n",
    "CLIPS_PER_VIDEO = MAX_FRAMES / FRAMES_PER_CLIP\n",
    "\n",
    "'''Self-defined gesture labels'''\n",
    "NO_GESTURE = 21\n",
    "EMPTY_PADDING = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sample = GestureSample(RAW_DATA_PATH + 'Train1/Sample0001.zip')\n",
    "#print(imresize(sample.getRGB(1)[10:330, 140:460], RESIZE_RATIO, interp='bilinear').shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(path, data_type, write_path, sample_ids, label_path = None):\n",
    "    \n",
    "    tf_file_itr = 1\n",
    "    tf_write_option = tf.python_io.TFRecordOptions(compression_type=tf.python_io.TFRecordCompressionType.GZIP)\n",
    "    \n",
    "    filename = '%s/%s%02d.tfrecords' % (write_path, data_type, tf_file_itr)\n",
    "    tf_writer = tf.python_io.TFRecordWriter('%s/%s%02d.tfrecords' % (write_path, data_type, tf_file_itr),options=tf_write_option)\n",
    "    \n",
    "    for sample_id in tqdm(sample_ids):\n",
    "        \n",
    "        '''Get ChaLearn Data reader'''\n",
    "        if label_path is not None: #data_type == 'Validation'\n",
    "            sample = GestureSample('%s/%s/Sample%04d.zip'%(path, data_type, sample_id), \n",
    "                                   labelFileName=label_path + 'Sample%04d_prediction.csv'%sample_id)\n",
    "        else: # data_type == 'Test', 'Train'\n",
    "            sample = GestureSample('%s/%s/Sample%04d.zip'%(path, data_type, sample_id))\n",
    "            \n",
    "        '''Get label per frame'''\n",
    "        gesture_list = sample.getGestures()\n",
    "        num_of_frames = sample.getNumFrames()\n",
    "        if (num_of_frames > MAX_FRAMES):\n",
    "            raise Exception('Sample %d has %d Frames (> MAX_FRAMES:%d)' %(sample_id, num_of_frames, MAX_FRAMES))\n",
    "            \n",
    "        label = [EMPTY_PADDING] + [NO_GESTURE]* num_of_frames + [EMPTY_PADDING] * (MAX_FRAMES - num_of_frames)\n",
    "        has_label = True if len(gesture_list) > 0 else False\n",
    "        for gesture_id, start_frame, end_frame in gesture_list:\n",
    "            label[start_frame:end_frame+1] = [gesture_id]*(end_frame + 1 - start_frame)\n",
    "        \n",
    "        '''Get sliced and cropped RGB data from the whole sample'''\n",
    "        rgb = [np.zeros(IMAGE_SIZE)]\n",
    "        for f in range(1, MAX_FRAMES+1):\n",
    "            if (f > num_of_frames): # Add 0 paddings\n",
    "                rgb_data = np.zeros(IMAGE_SIZE)\n",
    "            else: \n",
    "                segmentation_mask = sample.getUser(f)\n",
    "                if (segmentation_mask.sum() == 0):\n",
    "                    label[f] = EMPTY_PADDING\n",
    "                    print('Empty segmentation mask for Sample %d on frame %d' % (sample_id, f))\n",
    "                rgb_data = sample.getRGB(f) * segmentation_mask\n",
    "                rgb_data = rgb_data[CROP[0]:CROP[1], CROP[2]:CROP[3],:]\n",
    "                rgb_data = imresize(rgb_data, RESIZE_RATIO, interp='bilinear')\n",
    "            rgb += [rgb_data]\n",
    "            \n",
    "        '''Make it into clips'''\n",
    "        rgbs = []\n",
    "        labels = []\n",
    "        for f in range(1, MAX_FRAMES+1, FRAMES_PER_CLIP):\n",
    "            rgbs += [np.asarray(rgb[f:f+FRAMES_PER_CLIP])]\n",
    "            labels += [int(stats.mode(label[f:f+FRAMES_PER_CLIP])[0])]\n",
    "            \n",
    "        '''Create TFRecord structure'''\n",
    "        context = tf.train.Features(feature={'sample_id': util._int64_feature(sample_id)})\n",
    "            \n",
    "        if has_label:\n",
    "            featureLists = tf.train.FeatureLists(feature_list={\n",
    "                'rgbs':util._bytes_feature_list(rgbs),\n",
    "                'labels':util._int64_feature_list(labels)\n",
    "            })\n",
    "        else:\n",
    "            featureLists = tf.train.FeatureLists(feature_list={'rgbs':util._bytes_feature_list(rgbs)})\n",
    "       \n",
    "        sequence_example = tf.train.SequenceExample(context=context, feature_lists=featureLists)\n",
    "        \n",
    "        '''Write to .tfrecord file'''\n",
    "        tf_writer.write(sequence_example.SerializeToString())\n",
    "        if sample_id % 100 == 0:\n",
    "            tf_writer.close()\n",
    "            tf_file_itr += 1\n",
    "            tf_writer = tf.python_io.TFRecordWriter('%s/%s%02d.tfrecords' %(write_path, data_type, tf_file_itr), \n",
    "                                                    options=tf_write_option)\n",
    "\n",
    "    tf_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:33<05:02, 33.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty segmentation mask for Sample 472 on frame 1\n",
      "Empty segmentation mask for Sample 472 on frame 2\n",
      "Empty segmentation mask for Sample 472 on frame 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [01:57<04:29, 38.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty segmentation mask for Sample 474 on frame 1\n",
      "Empty segmentation mask for Sample 474 on frame 2\n",
      "Empty segmentation mask for Sample 474 on frame 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [02:22<03:27, 34.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty segmentation mask for Sample 475 on frame 1\n",
      "Empty segmentation mask for Sample 475 on frame 2\n",
      "Empty segmentation mask for Sample 475 on frame 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [02:53<02:47, 33.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty segmentation mask for Sample 476 on frame 1\n",
      "Empty segmentation mask for Sample 476 on frame 2\n",
      "Empty segmentation mask for Sample 476 on frame 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [03:19<02:05, 31.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty segmentation mask for Sample 477 on frame 1\n",
      "Empty segmentation mask for Sample 477 on frame 2\n",
      "Empty segmentation mask for Sample 477 on frame 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [03:45<01:29, 29.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty segmentation mask for Sample 478 on frame 1\n",
      "Empty segmentation mask for Sample 478 on frame 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:24<00:00, 31.89s/it]\n"
     ]
    }
   ],
   "source": [
    "#get_data(RAW_DATA_PATH, 'Train', TFRecord_DATA_PATH, TRAIN_ID)\n",
    "get_data(RAW_DATA_PATH, 'Validation', TFRecord_DATA_PATH, VALIDATION_ID, label_path = RAW_DATA_PATH + 'Validation_reference/')\n",
    "#get_data(RAW_DATA_PATH + '/Train', TRAIN_LIST)\n",
    "#get_data(RAW_DATA_PATH + '/Train', TRAIN_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
