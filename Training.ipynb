{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_ID = range(1,11)         # Raw file format : Sample0001.zip - Sample0470.zip\n",
    "VALIDATION_ID = range(471,481)  # Raw file format : Sample0471.zip - Sample0700.zip\n",
    "TEST_ID = range(701,711)        # Raw file format : Sample0701.zip - Sample0941.zip\n",
    "# TRAIN_LIST = range(1,471)         # Raw file format : Sample0001.zip - Sample0470.zip\n",
    "# VALIDATION_LIST = range(471,701)  # Raw file format : Sample0471.zip - Sample0700.zip\n",
    "# TEST_LIST = range(701,941)        # Raw file format : Sample0701.zip - Sample0941.zip\n",
    "\n",
    "IMAGE_SIZE = (80, 80, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TFRecord_DATA_PATH = './tf-data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FRAMES_PER_CLIP = 5\n",
    "MAX_FRAMES = 2000\n",
    "CLIPS_PER_VIDEO = MAX_FRAMES / FRAMES_PER_CLIP\n",
    "\n",
    "'''Self-defined gesture labels'''\n",
    "NO_GESTURE = 21\n",
    "EMPTY_PADDING = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Training parameters'''\n",
    "NUM_EPOCHS = 1\n",
    "NUM_READ_THREADS = 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing_op(image_op):\n",
    "    '''most preprocess should be done while making the .tfrecords files?'''\n",
    "    with tf.name_scope('preprocessing'):\n",
    "        # Reshape serialized image\n",
    "        image_op = tf.reshape(image_op, IMAGE_SIZE)\n",
    "        # Integer to float\n",
    "        image_op = tf.to_float(image_op)\n",
    "        # Normalize (Zero-mean unit-variance) on single image\n",
    "        image_op = tf.image.per_image_standardization(image_op)\n",
    "        \n",
    "        return image_op\n",
    "    \n",
    "def read_and_decode(filename_queue):\n",
    "    readerOptions = tf.python_io.TFRecordOptions(compression_type=tf.python_io.TFRecordCompressionType.GZIP)\n",
    "    reader = tf.TFRecordReader(options=readerOptions)\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    \n",
    "    with tf.name_scope('TFRecordDecoding'):\n",
    "        context_encoded, features_encoded = tf.parse_single_sequence_example(\n",
    "            serialized_example,\n",
    "            context={'sample_id': tf.FixedLenFeature([], dtype=tf.int64)},\n",
    "            feature={'rgb':tf.FixedLenSequenceFeature([],dtype=tf.string), # TODO: check string or bytes\n",
    "                     'label':tf.FixedLenSequenceFeature([], dtype=tf.string)} # TODO: check string or bytes\n",
    "        )\n",
    "        seq_rgb = tf.decode_raw(features_encoded['rgb'], tf.int64)\n",
    "        seq_label = tf.decode_raw(features_encoded['label'], tf.int64)\n",
    "        # apply preprocessing to single image using map_fn\n",
    "        seq_rgb = tf.map_fn(lambda x: preprocessing_op(x), elems = seq_rgb, dtype=tf.float32, back_prop=False)\n",
    "        #TODO : back_pop = false??\n",
    "        \n",
    "        return [seq_rgb, seq_label]\n",
    "\n",
    "def input_pipeline(filenames):\n",
    "    with tf.name_scope('input_pipeline'):\n",
    "        # Create a input file queue\n",
    "        filename_queue = tf.train.string_input_producer(filenames, num_epochs=NUM_EPOCHS, shuffle=True)\n",
    "        \n",
    "        # Read data from .tfreords files and decode to a list of samples (Using threads)\n",
    "        samples = [read_and_decode(filename_queue) for _ in range(NUM_READ_THREADS)]\n",
    "        \n",
    "        # Create batches\n",
    "        # batch_join is used for N threads, can use batch_join_shuffle too\n",
    "        batch_rgb, batch_labels = tf.train.batch_join(samples, \n",
    "                                                      batch_size = BATCH_SIZE,\n",
    "                                                      capacity = QUEUE_CAPACITY,\n",
    "                                                      enqueue_many= False, \n",
    "                                                      dynamic_pad = False, # make true if each data has different size\n",
    "                                                      name = 'batch_join')\n",
    "        return batch_rgb, batch_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
