{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "TRAIN_ID = range(3,11)         # Raw file format : Sample0001.zip - Sample0470.zip\n",
    "VALIDATION_ID = range(471,481)  # Raw file format : Sample0471.zip - Sample0700.zip\n",
    "TEST_ID = range(701,711)        # Raw file format : Sample0701.zip - Sample0941.zip\n",
    "# TRAIN_LIST = range(1,471)         # Raw file format : Sample0001.zip - Sample0470.zip\n",
    "# VALIDATION_LIST = range(471,701)  # Raw file format : Sample0471.zip - Sample0700.zip\n",
    "# TEST_LIST = range(701,941)        # Raw file format : Sample0701.zip - Sample0941.zip\n",
    "\n",
    "IMAGE_SIZE = (80, 80, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "TFRecord_DATA_PATH = './tf-data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "FRAMES_PER_CLIP = 8 \n",
    "MAX_FRAMES = 2000\n",
    "CLIPS_PER_VIDEO = int(MAX_FRAMES / FRAMES_PER_CLIP)\n",
    "\n",
    "'''Self-defined gesture labels'''\n",
    "NO_GESTURE = 21\n",
    "EMPTY_PADDING = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''Training parameters'''\n",
    "NUM_EPOCHS = 1\n",
    "NUM_READ_THREADS = 1\n",
    "BATCH_SIZE = 1\n",
    "QUEUE_CAPACITY = BATCH_SIZE * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def preprocessing_op(image_op):\n",
    "    '''most preprocess should be done while making the .tfrecords files?'''\n",
    "    with tf.name_scope('preprocessing'):\n",
    "        # Reshape serialized image\n",
    "        image_op = tf.reshape(image_op, [CLIPS_PER_VIDEO] + list(IMAGE_SIZE))\n",
    "        # Integer to float\n",
    "        image_op = tf.to_float(image_op)\n",
    "        # Normalize (Zero-mean unit-variance) on single image\n",
    "        image_op = tf.map_fn(lambda img: tf.image.per_image_standardization(img), image_op)\n",
    "        \n",
    "        return image_op\n",
    "    \n",
    "def read_and_decode(filename_queue):\n",
    "    readerOptions = tf.python_io.TFRecordOptions(compression_type=tf.python_io.TFRecordCompressionType.GZIP)\n",
    "    reader = tf.TFRecordReader(options=readerOptions)\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    \n",
    "    with tf.name_scope('TFRecordDecoding'):\n",
    "        context_encoded, features_encoded = tf.parse_single_sequence_example(\n",
    "            serialized_example,\n",
    "            context_features={'sample_id': tf.FixedLenFeature([], dtype=tf.int64)},\n",
    "            sequence_features={'rgbs':tf.FixedLenSequenceFeature([],dtype=tf.string), # TODO: check string or bytes\n",
    "                     'labels':tf.FixedLenSequenceFeature([], dtype=tf.int64)} # TODO: check string or bytes\n",
    "        )\n",
    "        seq_rgb = tf.decode_raw(features_encoded['rgbs'], tf.uint8)\n",
    "        #seq_rgb = np.zeros([1, CLIPS_PER_VIDEO, FRAMES_PER_CLIP, 80, 80, 3])\n",
    "        seq_label = features_encoded['labels']\n",
    "        print(features_encoded['rgbs'])\n",
    "        print(features_encoded['labels'])\n",
    "        # apply preprocessing to single image using map_fn\n",
    "        seq_rgb = tf.map_fn(lambda x: preprocessing_op(x), elems = seq_rgb, dtype=tf.float32, back_prop=False)\n",
    "        \n",
    "        return [seq_rgb, seq_label]\n",
    "    \n",
    "\n",
    "def input_pipeline(filenames, data_type):\n",
    "    \n",
    "    with tf.name_scope('input_pipeline'):\n",
    "        # Create a input file queue\n",
    "        filename_queue = tf.train.string_input_producer(filenames, num_epochs=NUM_EPOCHS, shuffle=True)\n",
    "        \n",
    "        # Read data from .tfreords files and decode to a list of samples (Using threads)\n",
    "        samples = [read_and_decode(filename_queue) for _ in range(NUM_READ_THREADS)]\n",
    "        \n",
    "        # Create batches\n",
    "        # batch_join is used for N threads, can use batch_join_shuffle too\n",
    "        batch_rgb, batch_labels = tf.train.batch_join(samples, \n",
    "                                                      batch_size = BATCH_SIZE,\n",
    "                                                      capacity = QUEUE_CAPACITY,\n",
    "                                                      shapes = None,#[[BATCH_SIZE, CLIPS_PER_VIDEO] + list(IMAGE_SIZE), [BATCH_SIZE, CLIPS_PER_VIDEO]],\n",
    "                                                      enqueue_many= False, \n",
    "                                                      dynamic_pad = True, \n",
    "                                                      name = 'batch_join')\n",
    "        if (data_type == 'Train' or data_type == 'Validation'):\n",
    "            return batch_rgb, batch_labels\n",
    "        else:\n",
    "            return batch_rgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def look_into_tfRecords(filenames, data_type):\n",
    "    %matplotlib inline\n",
    "\n",
    "    batch_samples_op, batch_labels_op = input_pipeline(filenames, data_type)\n",
    "\n",
    "    sess = tf.Session()\n",
    "    init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "    sess.run(init_op)\n",
    "    # Create threads to prefetch the data\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    batch_samples, batch_labels = sess.run([batch_samples_op, batch_labels_op])\n",
    "    \n",
    "    \n",
    "    # Print \n",
    "    print(\"# Samples: \" + str(len(batch_samples)))\n",
    "    print(\"Sequence labels: \" + str(batch_labels))\n",
    "\n",
    "    # Note that the second dimension will give maximum-length in the batch, i.e., the padded sequence length.\n",
    "    print(\"Sequence type: \" + str(type(batch_samples)))\n",
    "    print(\"Sequence shape: \" + str(batch_samples.shape))\n",
    "\n",
    "    # Fetch first clips 11th frame.\n",
    "    img = batch_samples[0][0]\n",
    "    print(\"Image shape: \" + str(img.shape))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img) # Note that image may look wierd because it is normalized.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_pipeline_3/TFRecordDecoding/ParseSingleSequenceExample/ParseSingleSequenceExample:2\", shape=(?,), dtype=string)\n",
      "Tensor(\"input_pipeline_3/TFRecordDecoding/ParseSingleSequenceExample/ParseSingleSequenceExample:1\", shape=(?,), dtype=int64)\n",
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, DecodeRaw requires input strings to all be the same size, but element 231 has size 153600 != 1228800\n",
      "\t [[Node: input_pipeline_3/TFRecordDecoding/DecodeRaw = DecodeRaw[little_endian=true, out_type=DT_UINT8, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input_pipeline_3/TFRecordDecoding/ParseSingleSequenceExample/ParseSingleSequenceExample:2)]]\n",
      "\n",
      "Caused by op 'input_pipeline_3/TFRecordDecoding/DecodeRaw', defined at:\n",
      "  File \"/usr/local/Cellar/python3/3.6.0_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/local/Cellar/python3/3.6.0_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 474, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/tornado/ioloop.py\", line 887, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2827, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-16-a0d3135dd676>\", line 5, in <module>\n",
      "    look_into_tfRecords(['%s/%s/Sample%04d.tfrecords' % (TFRecord_DATA_PATH, 'Train', i) for i in range(1,2)], 'Train')\n",
      "  File \"<ipython-input-15-d0ddc952059b>\", line 4, in look_into_tfRecords\n",
      "    batch_samples_op, batch_labels_op = input_pipeline(filenames, data_type)\n",
      "  File \"<ipython-input-14-be0e3899dbbe>\", line 43, in input_pipeline\n",
      "    samples = [read_and_decode(filename_queue) for _ in range(NUM_READ_THREADS)]\n",
      "  File \"<ipython-input-14-be0e3899dbbe>\", line 43, in <listcomp>\n",
      "    samples = [read_and_decode(filename_queue) for _ in range(NUM_READ_THREADS)]\n",
      "  File \"<ipython-input-14-be0e3899dbbe>\", line 25, in read_and_decode\n",
      "    seq_rgb = tf.decode_raw(features_encoded['rgbs'], tf.uint8)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_parsing_ops.py\", line 101, in decode_raw\n",
      "    little_endian=little_endian, name=name)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n",
      "    op_def=op_def)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n",
      "    original_op=self._default_original_op, op_def=op_def)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n",
      "    self._traceback = _extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): DecodeRaw requires input strings to all be the same size, but element 231 has size 153600 != 1228800\n",
      "\t [[Node: input_pipeline_3/TFRecordDecoding/DecodeRaw = DecodeRaw[little_endian=true, out_type=DT_UINT8, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input_pipeline_3/TFRecordDecoding/ParseSingleSequenceExample/ParseSingleSequenceExample:2)]]\n",
      "\n"
     ]
    },
    {
     "ename": "OutOfRangeError",
     "evalue": "PaddingFIFOQueue '_56_input_pipeline_3/batch_join/padding_fifo_queue' is closed and has insufficient elements (requested 1, current size 0)\n\t [[Node: input_pipeline_3/batch_join = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input_pipeline_3/batch_join/padding_fifo_queue, input_pipeline_3/batch_join/n)]]\n\nCaused by op 'input_pipeline_3/batch_join', defined at:\n  File \"/usr/local/Cellar/python3/3.6.0_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/Cellar/python3/3.6.0_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.6/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2827, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-16-a0d3135dd676>\", line 5, in <module>\n    look_into_tfRecords(['%s/%s/Sample%04d.tfrecords' % (TFRecord_DATA_PATH, 'Train', i) for i in range(1,2)], 'Train')\n  File \"<ipython-input-15-d0ddc952059b>\", line 4, in look_into_tfRecords\n    batch_samples_op, batch_labels_op = input_pipeline(filenames, data_type)\n  File \"<ipython-input-14-be0e3899dbbe>\", line 53, in input_pipeline\n    name = 'batch_join')\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/input.py\", line 1065, in batch_join\n    name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/input.py\", line 747, in _batch_join\n    dequeued = queue.dequeue_many(batch_size, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/data_flow_ops.py\", line 458, in dequeue_many\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 1328, in _queue_dequeue_many_v2\n    timeout_ms=timeout_ms, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nOutOfRangeError (see above for traceback): PaddingFIFOQueue '_56_input_pipeline_3/batch_join/padding_fifo_queue' is closed and has insufficient elements (requested 1, current size 0)\n\t [[Node: input_pipeline_3/batch_join = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input_pipeline_3/batch_join/padding_fifo_queue, input_pipeline_3/batch_join/n)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.0_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m: PaddingFIFOQueue '_56_input_pipeline_3/batch_join/padding_fifo_queue' is closed and has insufficient elements (requested 1, current size 0)\n\t [[Node: input_pipeline_3/batch_join = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input_pipeline_3/batch_join/padding_fifo_queue, input_pipeline_3/batch_join/n)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a0d3135dd676>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mVALIDATION_FILENAMES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'%s/%s/Sample%04d.tfrecords'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTFRecord_DATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Validation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mVALIDATION_ID\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlook_into_tfRecords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'%s/%s/Sample%04d.tfrecords'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTFRecord_DATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#look_into_tfRecords(TRAIN_FILENAMES + VALIDATION_FILENAMES, 'Train')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-d0ddc952059b>\u001b[0m in \u001b[0;36mlook_into_tfRecords\u001b[0;34m(filenames, data_type)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mthreads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_queue_runners\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mbatch_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_samples_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m: PaddingFIFOQueue '_56_input_pipeline_3/batch_join/padding_fifo_queue' is closed and has insufficient elements (requested 1, current size 0)\n\t [[Node: input_pipeline_3/batch_join = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input_pipeline_3/batch_join/padding_fifo_queue, input_pipeline_3/batch_join/n)]]\n\nCaused by op 'input_pipeline_3/batch_join', defined at:\n  File \"/usr/local/Cellar/python3/3.6.0_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/Cellar/python3/3.6.0_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.6/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2827, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-16-a0d3135dd676>\", line 5, in <module>\n    look_into_tfRecords(['%s/%s/Sample%04d.tfrecords' % (TFRecord_DATA_PATH, 'Train', i) for i in range(1,2)], 'Train')\n  File \"<ipython-input-15-d0ddc952059b>\", line 4, in look_into_tfRecords\n    batch_samples_op, batch_labels_op = input_pipeline(filenames, data_type)\n  File \"<ipython-input-14-be0e3899dbbe>\", line 53, in input_pipeline\n    name = 'batch_join')\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/input.py\", line 1065, in batch_join\n    name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/input.py\", line 747, in _batch_join\n    dequeued = queue.dequeue_many(batch_size, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/data_flow_ops.py\", line 458, in dequeue_many\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 1328, in _queue_dequeue_many_v2\n    timeout_ms=timeout_ms, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nOutOfRangeError (see above for traceback): PaddingFIFOQueue '_56_input_pipeline_3/batch_join/padding_fifo_queue' is closed and has insufficient elements (requested 1, current size 0)\n\t [[Node: input_pipeline_3/batch_join = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input_pipeline_3/batch_join/padding_fifo_queue, input_pipeline_3/batch_join/n)]]\n"
     ]
    }
   ],
   "source": [
    "TRAIN_FILENAMES = ['%s/%s/Sample%04d.tfrecords' % (TFRecord_DATA_PATH, 'Train', i) for i in TRAIN_ID]\n",
    "TEST_FILENAMES = ['%s/%s/Sample%04d.tfrecords' % (TFRecord_DATA_PATH, 'Test', i) for i in TEST_ID]\n",
    "VALIDATION_FILENAMES = ['%s/%s/Sample%04d.tfrecords' % (TFRecord_DATA_PATH, 'Validation', i) for i in VALIDATION_ID]\n",
    "\n",
    "look_into_tfRecords(['%s/%s/Sample%04d.tfrecords' % (TFRecord_DATA_PATH, 'Train', i) for i in range(1,2)], 'Train')\n",
    "#look_into_tfRecords(TRAIN_FILENAMES + VALIDATION_FILENAMES, 'Train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Create Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Set up flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Model Hyperparameters\n",
    "tf.flags.DEFINE_float(\"dropout_rate\", 0.5, \"Dropout rate (default: 0.5)\")\n",
    "# Training Parameters\n",
    "tf.flags.DEFINE_integer(\"learning_rate\", 5e-4, \"Batch Size (default: 1e-3)\")\n",
    "tf.flags.DEFINE_integer(\"batch_size\", 128, \"Batch Size (default: 32)\")\n",
    "tf.flags.DEFINE_integer(\"num_epochs\", 10000, \"Number of full passess over whole training data (default: 100)\")\n",
    "tf.flags.DEFINE_integer(\"print_every_step\", 200, \"Print training details after this many steps/iterations (i.e., batches) (default: 10)\")\n",
    "tf.flags.DEFINE_integer(\"evaluate_every_step\", 1000, \"Evaluate model on validation set after this many steps/iterations (i.e., batches) (default: 500)\")\n",
    "tf.flags.DEFINE_integer(\"checkpoint_every_step\", 1000, \"Save model after this many steps/iterations (i.e., batches) (default: 1000)\")\n",
    "tf.flags.DEFINE_string(\"log_dir\", \"./runs/\", \"Output directory (default: './runs/')\")\n",
    "tf.flags.DEFINE_integer(\"epoch_length\", int(data_split[0].shape[0]/tf.flags.FLAGS.batch_size), \"Batch Size (default: 1e-3)\")\n",
    "\n",
    "FLAGS = tf.flags.FLAGS\n",
    "FLAGS._parse_flags()\n",
    "print(\"\\nCommand-line Arguments:\")\n",
    "for attr, value in sorted(FLAGS.__flags.items()):\n",
    "    print(\"{}={}\".format(attr.upper(), value))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create Directory for this experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "timestamp = str(int(time.time()))\n",
    "FLAGS.model_dir = os.path.abspath(os.path.join(FLAGS.log_dir, timestamp))\n",
    "print(\"Writing to {}\\n\".format(FLAGS.model_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### set up placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Feed a batch of training data at each training step using the {feed_dict} argument in sess.run()\n",
    "input_samples_op = tf.placeholder(tf.float32, shape = [None, CLIPS_PER_VIDEO] + IMAGE_SHAPE, name='input_samples')\n",
    "input_labels_op = tf.placeholder(tf.int64, shape=[None, CLIPS_PER_VIDEO], name='input_labels')\n",
    "\n",
    "mode = tf.placeholder(tf.bool, name='mode') # Pass True in when it is in the trainging mode\n",
    "loss_avg = tf.placeholder(tf.float32, name='loss_avg')\n",
    "accuracy_avg = tf.placeholder(tf.float32, name='accuracy_avg')\n",
    "learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "\n",
    "# pass in parameters that controls external inputs\n",
    "# Returns 'logits' layer, the top-most layer of the network\n",
    "logits = models.conv_model_with_layers_api(input_samples_op, FLAGS.dropout_rate, mode)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Set up Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Count number of samples fed and correct predictions made.\n",
    "# Attached to a summary op\n",
    "counter_correct_prediction = tf.Varialbe(0, name='counter_correct_prediction', trainable=False)\n",
    "counter_samples_fed = tf.Variable(0, name='counter_samples_fed', trainable=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Loss calculations: cross-entropy\n",
    "# TODO : Change it to CTC loss\n",
    "with tf.name_scope('cross_entropy_loss'):\n",
    "    #loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=input_labels_op))\n",
    "\n",
    "# Accuracy calculations\n",
    "# TODO : Try to get a serialized output\n",
    "with tf.name_scope('accuracy'):\n",
    "    #predictions = tf.argmax(logits, 1, name='predictions')\n",
    "    #predictions = tf.Print(predictions,[predictions])\n",
    "    #correct_predictions = tf.nn.in_top_k(logits, input_labels_op, 1)\n",
    "    #batch_accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "    #num_correct_predictions = tf.reduce_sum(tf.cast(correct_predictions, tf.int32))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def do_evaluation(sess, samples, labels):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "TRAIN_FILENAMES = ['%s/%s/Sample%04d.tfrecords' % (TFRecord_DATA_PATH, 'Train', i) for i in TRAIN_ID]\n",
    "batch_samples_op, batch_labels_op = input_pipeline(TRAIN_FILENAMES, 'Train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def do_evaluation(sess, samples, labels):\n",
    "    batches = \n",
    "\n",
    "\n",
    "    def do_evaluation(sess, samples, labels):\n",
    "        '''\n",
    "        Evaluation function.\n",
    "        @param sess: tensorflow session object.\n",
    "        @param samples: input data (numpy tensor)\n",
    "        @param labels: ground-truth labels (numpy array)\n",
    "        '''\n",
    "        batches = utils.data_iterator(samples, labels, FLAGS.batch_size)\n",
    "        # Keep track of this run.\n",
    "        counter_accuracy = 0.0\n",
    "        counter_loss = 0.0\n",
    "        counter_batches = 0\n",
    "        for batch_samples, batch_labels in batches:\n",
    "            counter_batches += 1\n",
    "            feed_dict = {input_samples_op: batch_samples,\n",
    "                         input_label_op: batch_labels,\n",
    "                         mode: False}\n",
    "            results = sess.run([loss, num_correct_predictions], feed_dict=feed_dict)\n",
    "            counter_loss += results[0]\n",
    "            counter_accuracy += results[1]\n",
    "        return (counter_loss/counter_batches, counter_accuracy/(counter_batches*FLAGS.batch_size))\n",
    "\n",
    "    # Generate a variable to contain a counter for the global training step.\n",
    "    # Note that it is useful if you save/restore your network.\n",
    "    global_step = tf.Variable(1, name='global_step', trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
